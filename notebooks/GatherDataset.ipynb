{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afd1fe2-8931-4d2c-b12b-031772d384df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import data_utils\n",
    "\n",
    "\n",
    "# Define transformations to apply to the images (e.g., convert to tensor, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046ba6bc-9c5e-493c-8434-25847ecb9efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./data/\u001b[0m\n",
      "└── \u001b[01;34mMNIST\u001b[0m\n",
      "    └── \u001b[01;34mraw\u001b[0m\n",
      "        ├── t10k-images-idx3-ubyte\n",
      "        ├── \u001b[01;31mt10k-images-idx3-ubyte.gz\u001b[0m\n",
      "        ├── t10k-labels-idx1-ubyte\n",
      "        ├── \u001b[01;31mt10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "        ├── train-images-idx3-ubyte\n",
      "        ├── \u001b[01;31mtrain-images-idx3-ubyte.gz\u001b[0m\n",
      "        ├── train-labels-idx1-ubyte\n",
      "        └── \u001b[01;31mtrain-labels-idx1-ubyte.gz\u001b[0m\n",
      "\n",
      "3 directories, 8 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516dc9a8-1f61-48b0-ba56-c89187931421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transforms to create final tensors...\n",
      "Train tensors: torch.Size([60000, 1, 28, 28]), torch.Size([60000])\n",
      "Test tensors: torch.Size([10000, 1, 28, 28]), torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying transforms to create final tensors...\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "train_data, train_labels = next(iter(train_loader))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "test_data, test_labels = next(iter(test_loader))\n",
    "\n",
    "print(f\"Train tensors: {train_data.shape}, {train_labels.shape}\")\n",
    "print(f\"Test tensors: {test_data.shape}, {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83dede12-97aa-4671-8bee-049b5dfad447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "data_utils.split_and_distribute(\n",
       "    train_data,\n",
       "    train_labels,\n",
       "    test_data,\n",
       "    test_labels,\n",
       "    inventory_path: str,\n",
       "    split_method: str,\n",
       "    remote_dest_path: str,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Splits, saves, and distributes any dataset (provided as tensors or arrays) \n",
       "to Ansible clients.\n",
       "\n",
       "*** This will DELETE and REPLACE the remote_dest_path on all clients. ***\n",
       "\n",
       "Args:\n",
       "    train_data: A PyTorch Tensor or NumPy array of training data (X_train).\n",
       "    train_labels: A PyTorch Tensor or NumPy array of training labels (y_train).\n",
       "    test_data: A PyTorch Tensor or NumPy array of testing data (X_test).\n",
       "    test_labels: A PyTorch Tensor or NumPy array of testing labels (y_test).\n",
       "    inventory_path: Path to the inventory.ini file.\n",
       "    split_method: 'uniform', 'exponential', 'square', or 'linear'.\n",
       "    remote_dest_path: Absolute path on clients (e.g., \"/tmp/my_data\").\n",
       "\u001b[31mFile:\u001b[39m      ~/federated_learning/notebooks/utils/data_utils.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_utils.split_and_distribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8496eab0-3440-4732-9ff4-f196b0f309c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Split and Distribution ---\n",
      "Validating inputs...\n",
      "Querying Ansible inventory '/home/k3s-server-07/federated_learning/ansible/inventory.ini' for client list...\n",
      "Found 5 clients: ['k3s-client-09', 'k3s-client-08', 'k3s-client-17', 'k3s-client-18', 'k3s-client-06']\n",
      "\n",
      "Creating local splits in temporary directory: /tmp/tmppxc0tqid\n",
      "Splitting 60000 samples into 5 sites (square): [1090, 4363, 9818, 17454, 27275]\n",
      "  Saved 1090 items to /tmp/tmppxc0tqid/k3s-client-09_train.pt\n",
      "  Saved 4363 items to /tmp/tmppxc0tqid/k3s-client-08_train.pt\n",
      "  Saved 9818 items to /tmp/tmppxc0tqid/k3s-client-17_train.pt\n",
      "  Saved 17454 items to /tmp/tmppxc0tqid/k3s-client-18_train.pt\n",
      "  Saved 27275 items to /tmp/tmppxc0tqid/k3s-client-06_train.pt\n",
      "\n",
      "Saving full test dataset...\n",
      "  Saved 10000 items to /tmp/tmppxc0tqid/test_data.pt\n",
      "\n",
      "Starting distribution to clients via Ansible...\n",
      "  WARNING: Deleting remote directory '/tmp/mnist_data' on all clients...\n",
      "  Re-creating remote directory '/tmp/mnist_data'...\n",
      "  Distributing client-specific files...\n",
      "    Sending files to k3s-client-09...\n",
      "    Sending files to k3s-client-08...\n",
      "    Sending files to k3s-client-17...\n",
      "    Sending files to k3s-client-18...\n",
      "    Sending files to k3s-client-06...\n",
      "\n",
      "✅ Successfully distributed all files.\n",
      "--- Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "data_utils.split_and_distribute(\n",
    "    train_data=train_data,\n",
    "    train_labels=train_labels,\n",
    "    test_data=test_data,\n",
    "    test_labels=test_labels,\n",
    "    inventory_path=\"/home/k3s-server-07/federated_learning/ansible/inventory.ini\",\n",
    "    split_method=\"square\",\n",
    "    remote_dest_path=\"/tmp/mnist_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9850e06-ee30-450a-b8b9-9875c9ac7a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
