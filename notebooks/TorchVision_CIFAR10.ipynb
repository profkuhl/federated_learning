{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ba3d0-5254-47a8-bea2-a5c8e5fa4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_CLASSES = 10 \n",
    "\n",
    "print(f\"Instantiating ResNet18 model structure for {NUM_CLASSES} classes...\")\n",
    "\n",
    "model = models.resnet18(weights=None)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "\n",
    "print(\"Model structure is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f97e56-53d8-4904-9014-97fbdc5277b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from torchvision.models import ResNet\n",
    "from torchvision.models._utils import _ovewrite_named_param\n",
    "from torchvision.models.resnet import BasicBlock, ResNet18_Weights\n",
    "\n",
    "\n",
    "class Resnet18(ResNet):\n",
    "    def __init__(self, num_classes, weights: Optional[ResNet18_Weights] = None, progress: bool = True, **kwargs: Any):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        weights = ResNet18_Weights.verify(weights)\n",
    "\n",
    "        if weights is not None:\n",
    "            _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
    "\n",
    "        super().__init__(BasicBlock, [2, 2, 2, 2], num_classes=num_classes, **kwargs)\n",
    "\n",
    "        if weights is not None:\n",
    "            super().load_state_dict(weights.get_state_dict(progress=progress))                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b87645d9-6ed0-4d6f-a17d-3a877812b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Instantiated custom Resnet18 for 10 classes.\n",
      "Checkpoint Keys: odict_keys(['model', 'meta_props', 'train_conf'])\n",
      "\n",
      "✅ Successfully loaded federated model weights!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "MODEL_PATH = '/home/k3s-server-07/federated_learning/workspace/example_project/prod_00/admin@nvidia.com/transfer/1752bb34-fe21-4b3f-b7ff-94e10e3a7cd0/workspace/app_server/FL_global_model.pt'\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "model = Resnet18(num_classes=NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"Instantiated custom Resnet18 for {NUM_CLASSES} classes.\")\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    print(f'Checkpoint Keys: {checkpoint.keys()}')\n",
    "\n",
    "    if 'model' in checkpoint:\n",
    "        weights = checkpoint['model']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        weights = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        # Assume the file is the state_dict itself\n",
    "        weights = checkpoint\n",
    "\n",
    "    # Load the weights into the model\n",
    "    model.load_state_dict(weights)\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    print(\"\\n✅ Successfully loaded federated model weights!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ An error occurred: {e}\")\n",
    "    print(\"Ensure 'resnet_18.py' is present and matches the training model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96c28e7-47d3-4d4a-aba4-0dcf027112c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample inference...\n",
      "Model output shape: torch.Size([1, 10])\n",
      "Predicted class index: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Running sample inference...\")\n",
    "\n",
    "# preprocess will be used for pictures not in the cifar10\n",
    "# dataset to resize to 32x32\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # output = model(processed_img) \n",
    "    output = model(dummy_input)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    predicted_class_index = torch.argmax(probabilities).item()\n",
    "\n",
    "print(f\"Model output shape: {output.shape}\")\n",
    "print(f\"Predicted class index: {predicted_class_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7408dfe8-4bf2-4f82-ac47-86d9967a5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load the training and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e65d716c-f1d5-4062-8857-75a57a1eb7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on test set...\n",
      "\n",
      "Accuracy of the network on the 10000 test images: 78.3 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(\"Starting evaluation on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        \n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'\\nAccuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b9218-2809-4e9a-821b-4a85acfbd544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyVenv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
